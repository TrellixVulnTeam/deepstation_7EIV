{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習準備用\n",
    "引数からパラメータと活性化関数を与える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import chainer\n",
    "from chainer import optimizers\n",
    "#from chainer import serializers\n",
    "import net\n",
    "\n",
    "import trainer\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='CIFAR-10 dataset trainer')\n",
    "    parser.add_argument('--gpu', '-g', type=int, default=-1,\n",
    "                        help='GPU device ID (negative value indicates CPU)')\n",
    "    parser.add_argument('--model', '-m', type=str, default='vgg', choices=['cnn', 'cnnbn', 'cnnwn', 'vgg', 'residual', 'identity_mapping', 'vgg_no_fc', 'vgg_wide', 'vgg_crelu', 'inception', 'pyramid'],\n",
    "                        help='Model name')\n",
    "    parser.add_argument('--batch_size', '-b', type=int, default=100,\n",
    "                        help='Mini batch size')\n",
    "    parser.add_argument('--dataset', '-d', type=str, default='dataset/image.pkl',\n",
    "                        help='Dataset image pkl file path')\n",
    "    parser.add_argument('--label', '-l', type=str, default='dataset/label.pkl',\n",
    "                        help='Dataset label pkl file path')\n",
    "    parser.add_argument('--prefix', '-p', type=str, default=None,\n",
    "                        help='Prefix of model parameter files')\n",
    "    parser.add_argument('--iter', type=int, default=300,\n",
    "                        help='Training iteration')\n",
    "    parser.add_argument('--save_iter', type=int, default=0,\n",
    "                        help='Iteration interval to save model parameter file.')\n",
    "    parser.add_argument('--lr_decay_iter', type=str, default='100',\n",
    "                        help='Iteration interval to decay learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0001,\n",
    "                        help='Weight decay')\n",
    "    parser.add_argument('--optimizer', type=str, default='sgd', choices=['sgd', 'adam'],\n",
    "                        help='Optimizer name')\n",
    "    parser.add_argument('--lr', type=float, default=0.01,\n",
    "                        help='Initial learning rate for SGD')\n",
    "    parser.add_argument('--alpha', type=float, default=0.001,\n",
    "                        help='Initial alpha for Adam')\n",
    "    parser.add_argument('--res_depth', type=int, default=18,\n",
    "                        help='Depth of Residual Network')\n",
    "    parser.add_argument('--skip_depth', action='store_true',\n",
    "                        help='Use stochastic depth in Residual Network')\n",
    "    parser.add_argument('--swapout', action='store_true',\n",
    "                        help='Use swapout')\n",
    "    parser.add_argument('--seed', type=int, default=1,\n",
    "                        help='Random seed')\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    np.random.seed(args.seed)\n",
    "    log_file_path = '{}_log.csv'.format(args.prefix)\n",
    "    lr_decay_iter = map(int, args.lr_decay_iter.split(','))\n",
    "\n",
    "    print('loading dataset...')\n",
    "    with open(args.dataset, 'rb') as f:\n",
    "        images = pickle.load(f)\n",
    "        index = np.random.permutation(len(images['train']))\n",
    "        train_index = index[:-5000]\n",
    "        valid_index = index[-5000:]\n",
    "        train_x = images['train'][train_index].reshape((-1, 3, 32, 32))\n",
    "        valid_x = images['train'][valid_index].reshape((-1, 3, 32, 32))\n",
    "        test_x = images['test'].reshape((-1, 3, 32, 32))\n",
    "    with open(args.label, 'rb') as f:\n",
    "        labels = pickle.load(f)\n",
    "        train_y = labels['train'][train_index]\n",
    "        valid_y = labels['train'][valid_index]\n",
    "        test_y = labels['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    print('start training')\n",
    "    if args.model == 'cnn':\n",
    "        cifar_net = net.CNN()\n",
    "    elif args.model == 'cnnbn':\n",
    "        cifar_net = net.CNNBN()\n",
    "    elif args.model == 'cnnwn':\n",
    "        cifar_net = net.CNNWN()\n",
    "    elif args.model == 'residual':\n",
    "        cifar_net = net.ResidualNet(args.res_depth, swapout=args.swapout, skip=args.skip_depth)\n",
    "    elif args.model == 'identity_mapping':\n",
    "        cifar_net = net.IdentityMapping(args.res_depth, swapout=args.swapout, skip=args.skip_depth)\n",
    "    elif args.model == 'vgg_no_fc':\n",
    "        cifar_net = net.VGGNoFC()\n",
    "    elif args.model == 'vgg_wide':\n",
    "        cifar_net = net.VGGWide()\n",
    "    elif args.model == 'vgg_crelu':\n",
    "        cifar_net = net.VGGCReLU()\n",
    "    elif args.model == 'inception':\n",
    "        cifar_net = net.Inception()\n",
    "    elif args.model == 'pyramid':\n",
    "        cifar_net = net.PyramidNet(args.res_depth, skip=args.skip_depth)\n",
    "    else:\n",
    "        cifar_net = net.VGG()\n",
    "\n",
    "    if args.optimizer == 'sgd':\n",
    "        optimizer = optimizers.MomentumSGD(lr=args.lr)\n",
    "    else:\n",
    "        optimizer = optimizers.Adam(alpha=args.alpha)\n",
    "    optimizer.setup(cifar_net)\n",
    "    if args.weight_decay > 0:\n",
    "        optimizer.add_hook(chainer.optimizer.WeightDecay(args.weight_decay))\n",
    "    cifar_trainer = trainer.CifarTrainer(cifar_net, optimizer, args.iter, args.batch_size, args.gpu)\n",
    "    if args.prefix is None:\n",
    "        model_prefix = '{}_{}'.format(args.model, args.optimizer)\n",
    "    else:\n",
    "        model_prefix = args.prefix\n",
    "\n",
    "    state = {'best_valid_error': 100, 'best_test_error': 100, 'clock': time.clock()}\n",
    "    def on_epoch_done(epoch, n, o, loss, acc, valid_loss, valid_acc, test_loss, test_acc):\n",
    "        error = 100 * (1 - acc)\n",
    "        valid_error = 100 * (1 - valid_acc)\n",
    "        test_error = 100 * (1 - test_acc)\n",
    "        print('epoch {} done'.format(epoch))\n",
    "        print('train loss: {} error: {}'.format(loss, error))\n",
    "        print('valid loss: {} error: {}'.format(valid_loss, valid_error))\n",
    "        print('test  loss: {} error: {}'.format(test_loss, test_error))\n",
    "        if valid_error < state['best_valid_error']:\n",
    "            serializers.save_npz('{}.model'.format(model_prefix), n)\n",
    "            serializers.save_npz('{}.state'.format(model_prefix), o)\n",
    "            state['best_valid_error'] = valid_error\n",
    "            state['best_test_error'] = test_error\n",
    "        if args.save_iter > 0 and (epoch + 1) % args.save_iter == 0:\n",
    "            serializers.save_npz('{}_{}.model'.format(model_prefix, epoch + 1), n)\n",
    "            serializers.save_npz('{}_{}.state'.format(model_prefix, epoch + 1), o)\n",
    "        # prevent divergence when using identity mapping model\n",
    "        if args.model == 'identity_mapping' and epoch < 9:\n",
    "            o.lr = 0.01 + 0.01 * (epoch + 1)\n",
    "        if len(lr_decay_iter) == 1 and (epoch + 1) % lr_decay_iter[0] == 0 or epoch + 1 in lr_decay_iter:\n",
    "            if hasattr(optimizer, 'alpha'):\n",
    "                o.alpha *= 0.1\n",
    "            else:\n",
    "                o.lr *= 0.1\n",
    "        clock = time.clock()\n",
    "        print('elapsed time: {}'.format(clock - state['clock']))\n",
    "        state['clock'] = clock\n",
    "        with open(log_file_path, 'a') as f:\n",
    "            f.write('{},{},{},{},{},{},{}\\n'.format(epoch + 1, loss, error, valid_loss, valid_error, test_loss, test_error))\n",
    "\n",
    "    with open(log_file_path, 'w') as f:\n",
    "        f.write('epoch,train loss,train acc,valid loss,valid acc,test loss,test acc\\n')\n",
    "    cifar_trainer.fit(train_x, train_y, valid_x, valid_y, test_x, test_y, on_epoch_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    print('best test error: {in loss', c='blue')\n",
    "    ax.plot(xs, test_loss, label='test loss', c='red')\n",
    "    ax.set_xlim((1, epoch))\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.savefig('{}_loss.png'.format(args.prefix), bbox_inches='tight')\n",
    "\n",
    "    plt.clf()\n",
    "    fig, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
